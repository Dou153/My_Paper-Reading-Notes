{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img src=\"./assets/course-icon.png\" style=\"height:50px;display:inline\"> Learning Methods of Deep Learning\n",
    "---\n",
    "\n",
    "create by Deepfinder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
    "---\n",
    "\n",
    "1. 师徒相授：有监督学习（Supervised Learning）\n",
    "2. 见微知著：无监督学习（Un-supervised Learning）\n",
    "3. 无师自通：自监督学习（Self-supervised Learning）\n",
    "4. **以点带面：半监督学习（Semi-supervised learning）**\n",
    "5. 明辨是非：对比学习（Contrastive Learning）\n",
    "6. 举一反三：迁移学习（Transfer Learning）\n",
    "7. 针锋相对：对抗学习（Adversarial Learning）\n",
    "8. 众志成城：集成学习(Ensemble Learning) \n",
    "9. 殊途同归：联邦学习（Federated Learning）\n",
    "10. 百折不挠：强化学习（Reinforcement Learning）\n",
    "11. 求知若渴：主动学习（Active Learning）\n",
    "12. 万法归宗：元学习（Meta-Learning）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 04 - 以点带面：半监督学习（Semi-supervised learning）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "半监督学习（Semi-Supervised Learning）是指在仅有一部分样本带有人工标注、而大部分样本是无标注的场景下，仍能有效利用全部数据（有标注 + 无标注）进行模型训练的方法。它既利用了有监督学习中“有标注数据”的信息，又充分挖掘了无标注数据潜在的结构或分布特征，从而提升模型性能。\n",
    "\n",
    "下面介绍常见的半监督学习主要途径及思路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 自训练 (Self-Training) / 伪标签 (Pseudo-Labeling)**\n",
    "\n",
    "**核心思路**\n",
    "* 用当前模型为无标注数据生成“伪标签”，再把它们当做“带标签数据”一起加入训练，迭代更新模型。\n",
    "* 具体做法是：先用少量有标注数据训练一个初始模型，然后让模型在无标注数据上做预测，将高置信度的预测结果当作伪标签加入训练集中，再重新训练模型。\n",
    "\n",
    "**代表方法**\n",
    "* Self-Training / 自训练: 最基础的做法：对无标注样本进行预测并过滤掉模型置信度低的样本，只保留置信度高的伪标签加入到新的训练集。\n",
    "* Pseudo-Labeling: Google Brain 提出的简单实现：让模型自己给无标注数据打标签，然后再把这些新生成的标签当作真标签来训练。\n",
    "\n",
    "**优势 & 局限**\n",
    "\n",
    "* 优点：实现简单，易于和其他方法结合。\n",
    "* 缺点：如果初始模型本身偏差大，产生的伪标签质量低，可能会被错误标签“污染”，出现训练退化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <img src=\"https://img.icons8.com/?size=100&id=91CnU00i6HLv&format=png&color=000000\" style=\"height:50px;display:inline\"> 如果模型初期预测有偏差，把错误预测当作“真标签”重新训练，可能会越训越错？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 一致性正则化 (Consistency Regularization)**\n",
    "\n",
    "**无标签数据的分布也会给我们带来一定的信息**\n",
    "\n",
    "**核心思路**\n",
    "* 假设： 同一个无标注样本在经过不同的扰动或增强后，模型的输出应该保持一致。将这种一致性误差作为正则项来约束模型，即要求模型对同一数据不同增强视图的预测结果差异尽可能小。\n",
    "\n",
    "**具体实现**\n",
    "- 在半监督学习里，通常有两个数据集:\n",
    "1. 有标注数据集 $D_L$ ：样本少，但每个都有标签。\n",
    "2. 无标注数据集 $D_U$ ：样本很多，没有标签。\n",
    "- 对 $D_L$ ，我们通常使用监督学习的损失函数（例如分类的交叉摘）：\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text {supervised }}=\\sum_{(x, y) \\in D_L} \\operatorname{CE}\\left(f_\\theta(x), y\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "这里 $f_\\theta$ 表示模型， CE 表示交叉熵。\n",
    "\n",
    "- 对 $D_U$ ，我们没有真实标签，却希望模型能\"有稳定的输出\"——也就是一致性正则化:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text {consistency }}=\\sum_{x \\in D_U} d\\left(f_\\theta\\left(\\operatorname{Aug}_1(x)\\right), f_\\theta\\left(\\operatorname{Aug}_2(x)\\right)\\right)\n",
    "$$\n",
    "\n",
    "- $\\mathrm{Aug}_1, \\mathrm{Aug}_2$ 是对同一无标注样本的两种随机增强/扰动方式；\n",
    "- $d(\\cdot, \\cdot)$ 可以是均方误差、KL 散度等度量函数，用来衡量两次增强后的预测分布差异。\n",
    "- 要求这两个增强视图的预测尽量相似，鼓励模型对\"同一个样本\"有一致的输出。\n",
    "\n",
    "- 综合起来，在训练阶段，会把上面两部分损失加权求和:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text {total }}=\\mathcal{L}_{\\text {supervised }}+\\lambda \\cdot \\mathcal{L}_{\\text {consistency }}\n",
    "$$\n",
    "\n",
    "- 其中 $\\lambda$ 是一个超参数，用来平衡监督损失和一致性损失的相对权重。\n",
    "- 这样就同时利用了有标注数据（提供类别区分的监督信号）和无标注数据（提供一致性正则约束，提升模型的判别能力和泛化能力）。\n",
    "\n",
    "**优势 & 局限**\n",
    "* 优点：能有效利用无标注数据的分布信息，尤其在计算机视觉中配合数据增强效果明显。\n",
    "* 缺点：一致性约束依赖合适的数据增强或扰动方式，对不同任务需要不同设计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 基于生成模型 (Generative Approaches)**\n",
    "\n",
    "**核心思路** \n",
    "\n",
    "- 学习数据的分布模型（如变分自编码器 VAE、GAN 等），在此过程中同时使用有标注和无标注数据，使得模型在捕捉数据分布的同时，也能区分不同类别。\n",
    "\n",
    "**代表方法** \n",
    "- VAE + 分类器：把 VAE 编码器得到的隐变量空间既用于重构无标注样本，也辅助分类器分辨类别。\n",
    "- Semi-Supervised GAN：在 GAN 框架中，引入一个判别器能够区分\"真实图像的类别\"和\"生成图像\"这两件事，从而在少量标签的情况下学习到有判别力的特征。\n",
    "\n",
    "**优势 \\& 局限** \n",
    "\n",
    "- 优点：生成式建模能更好地挖掘数据分布，对无标注数据的表示学习能力较强。\n",
    "- 缺点：GAN 或VAE 的稳定训练以及和分类任务结合的策略较为复杂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: cpu\n",
      "训练集图像数量: 50000\n",
      "测试集图像数量: 10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# ---------------------------\n",
    "# 1. 设置随机种子与设备\n",
    "# ---------------------------\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 2. 加载 CIFAR-10 数据\n",
    "# ---------------------------\n",
    "\n",
    "def load_cifar10_batch(file_path):\n",
    "    \"\"\"\n",
    "    加载单个 batch 文件，返回图像和标签。\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='bytes')\n",
    "        images = batch[b'data']  # shape: (10000, 3072)\n",
    "        labels = batch[b'labels'] if b'labels' in batch else batch[b'fine_labels']\n",
    "        \n",
    "        # 重塑图像为 (N, 3, 32, 32)\n",
    "        images = images.reshape(-1, 3, 32, 32)\n",
    "        images = images.astype(np.float32) / 255.0  # 归一化到 [0,1]\n",
    "        \n",
    "        # 转换为 Tensor\n",
    "        images = torch.tensor(images)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    return images, labels\n",
    "\n",
    "def load_cifar10_data(data_dir):\n",
    "    \"\"\"\n",
    "    加载整个 CIFAR-10 数据集，返回训练集和测试集的图像与标签。\n",
    "    \"\"\"\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # 加载训练批次\n",
    "    for i in range(1, 6):\n",
    "        batch_file = os.path.join(data_dir, f'data_batch_{i}')\n",
    "        images, labels = load_cifar10_batch(batch_file)\n",
    "        train_images.append(images)\n",
    "        train_labels.append(labels)\n",
    "    \n",
    "    # 拼接所有训练批次\n",
    "    train_images = torch.cat(train_images, dim=0)  # shape: (50000, 3, 32, 32)\n",
    "    train_labels = torch.cat(train_labels, dim=0)  # shape: (50000,)\n",
    "    \n",
    "    # 加载测试批次\n",
    "    test_file = os.path.join(data_dir, 'test_batch')\n",
    "    test_images, test_labels = load_cifar10_batch(test_file)  # shape: (10000, 3, 32, 32), (10000,)\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# 指定 CIFAR-10 数据目录\n",
    "CIFAR10_DIR = './/dataset//cifar-10-python'  # 根据实际路径修改\n",
    "\n",
    "# 加载数据\n",
    "train_images_all, train_labels_all, test_images_all, test_labels_all = load_cifar10_data(CIFAR10_DIR)\n",
    "\n",
    "print(f\"训练集图像数量: {train_images_all.shape[0]}\")\n",
    "print(f\"测试集图像数量: {test_images_all.shape[0]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**部分标记的数据**\n",
    "\n",
    "您会注意到，数据集中的所有图像都已提供相应的标签。如果您使用所有数据训练模型，那么您将拥有一个完全监督的模型。\n",
    "\n",
    "本着半监督学习的精神，我们需要模拟缺乏标记数据的情况。一种简单的方法是提取一小部分图像及其相应的标签；然后您可以假装其他所有内容都没有标签。\n",
    "\n",
    "下面的代码提取了这个“监督”数据子集。请注意，所有对象类都有相同数量的提取样本。建议您从仅提取 1% 的数据集开始，以便测试和调试后续代码的速度更快。您当然可以在以后增加这一部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有标签数据数量: 500\n",
      "无标签数据数量: 49500\n",
      "有标签数据批次数: 8\n",
      "无标签数据批次数: 774\n",
      "验证/测试数据批次数: 157\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 3. 拆分“有标签”和“无标签”数据\n",
    "# ---------------------------\n",
    "\n",
    "NUM_LABELED_PER_CLASS = 50  # 每类有标签样本数\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# 初始化计数器\n",
    "count_per_class = [0] * NUM_CLASSES\n",
    "\n",
    "labeled_images = []\n",
    "labeled_labels = []\n",
    "unlabeled_images = []\n",
    "unlabeled_labels = []\n",
    "\n",
    "# 打乱索引以确保随机性\n",
    "indices = list(range(len(train_images_all)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "for idx in indices:\n",
    "    img = train_images_all[idx]\n",
    "    lbl = train_labels_all[idx].item()\n",
    "    \n",
    "    if count_per_class[lbl] < NUM_LABELED_PER_CLASS:\n",
    "        labeled_images.append(img)\n",
    "        labeled_labels.append(lbl)\n",
    "        count_per_class[lbl] += 1\n",
    "    else:\n",
    "        unlabeled_images.append(img)\n",
    "        unlabeled_labels.append(lbl)  # 标签仍然存在，但后续不使用\n",
    "\n",
    "print(f\"有标签数据数量: {len(labeled_images)}\")      # 预计: 10 * 50 = 500\n",
    "print(f\"无标签数据数量: {len(unlabeled_images)}\")    # 预计: 50000 - 500 = 49500\n",
    "\n",
    "# ---------------------------\n",
    "# 4. 定义 PyTorch Dataset 类\n",
    "# ---------------------------\n",
    "\n",
    "class LabeledCIFARDataset(Dataset):\n",
    "    \"\"\"\n",
    "    有标签数据集\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, images, labels):\n",
    "        \"\"\"\n",
    "        有标签数据集\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "\n",
    "class UnlabeledCIFARDataset(Dataset):\n",
    "    \"\"\"\n",
    "    无标签数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, images):\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        return x\n",
    "\n",
    "class CIFARValDataset(Dataset):\n",
    "    \"\"\"\n",
    "    验证/测试数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels):\n",
    "\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.images[idx]\n",
    "        y = self.labels[idx]\n",
    "        return x, y\n",
    "\n",
    "# ---------------------------\n",
    "# 5. 创建 DataLoader\n",
    "# ---------------------------\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 有标签 DataLoader\n",
    "labeled_dataset = LabeledCIFARDataset(labeled_images, labeled_labels)\n",
    "labeled_loader = DataLoader(\n",
    "    labeled_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 无标签 DataLoader\n",
    "unlabeled_dataset = UnlabeledCIFARDataset(unlabeled_images)\n",
    "unlabeled_loader = DataLoader(\n",
    "    unlabeled_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# 验证/测试 DataLoader\n",
    "val_dataset = CIFARValDataset(test_images_all, test_labels_all)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"有标签数据批次数: {len(labeled_loader)}\")      # 500 / 64 ≈ 8\n",
    "print(f\"无标签数据批次数: {len(unlabeled_loader)}\")    # 49500 / 64 ≈ 774\n",
    "print(f\"验证/测试数据批次数: {len(val_loader)}\")      # 10000 / 64 ≈ 157"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义模型架构**\n",
    "\n",
    "现在我们已经准备好了数据，让我们将注意力转向模型架构。请记住，我们的目标不是从我们拥有的数据中获得最佳性能，而是专注于学习如何实施半监督技术。考虑到这一点，我们将研究能够从头开始构建的简单toy model。\n",
    "\n",
    "您现在应该熟悉各种半监督技术。这里我们以VAE + 分类器为例子，可以针对两个不同的任务进行训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./assets/sst.png\" style=\"height:400px\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6. 定义模型（VAE + 分类器）\n",
    "# ---------------------------\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)  # [B, 16, 16, 16]\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1) # [B, 32, 8, 8]\n",
    "        self.fc = nn.Linear(32*8*8, 128)\n",
    "        self.mu_layer = nn.Linear(128, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(128, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.conv1(x))  # [B, 16, 16, 16]\n",
    "        h = F.relu(self.conv2(h))  # [B, 32, 8, 8]\n",
    "        h = h.view(h.size(0), -1)  # [B, 32*8*8]\n",
    "        h = F.relu(self.fc(h))     # [B, 128]\n",
    "        mu = self.mu_layer(h)      # [B, latent_dim]\n",
    "        logvar = self.logvar_layer(h)  # [B, latent_dim]\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 32*8*8)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1)  # [B,16,16,16]\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, 3, 4, stride=2, padding=1)   # [B,3,32,32]\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.fc(z))              # [B, 32*8*8]\n",
    "        h = h.view(h.size(0), 32, 8, 8)     # [B, 32, 8, 8]\n",
    "        h = F.relu(self.deconv1(h))         # [B, 16, 16, 16]\n",
    "        x_recon = torch.sigmoid(self.deconv2(h))  # [B, 3, 32, 32]\n",
    "        return x_recon\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, latent_dim=32, num_classes=10):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = F.relu(self.fc1(z))  # [B, 64]\n",
    "        logits = self.fc2(h)     # [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "class VAE_Classifier(nn.Module):\n",
    "    def __init__(self, latent_dim=32, num_classes=10):\n",
    "        super(VAE_Classifier, self).__init__()\n",
    "        self.encoder = Encoder(latent_dim)\n",
    "        self.decoder = Decoder(latent_dim)\n",
    "        self.classifier = Classifier(latent_dim, num_classes)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)    # [B, latent_dim]\n",
    "        eps = torch.randn_like(std)      # [B, latent_dim]\n",
    "        return mu + eps * std            # [B, latent_dim]\n",
    "\n",
    "    def forward_vae(self, x):\n",
    "        mu, logvar = self.encoder(x)             # [B, latent_dim], [B, latent_dim]\n",
    "        z = self.reparameterize(mu, logvar)      # [B, latent_dim]\n",
    "        x_recon = self.decoder(z)                # [B, 3, 32, 32]\n",
    "        return x_recon, mu, logvar, z\n",
    "\n",
    "    def forward_classifier(self, x):\n",
    "        mu, logvar = self.encoder(x)             # [B, latent_dim], [B, latent_dim]\n",
    "        logits = self.classifier(mu)             # [B, num_classes]\n",
    "        return logits\n",
    "\n",
    "# 实例化模型\n",
    "latent_dim = 32\n",
    "num_classes = 10\n",
    "model = VAE_Classifier(latent_dim=latent_dim, num_classes=num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 训练阶段的\"两条损失\"**\n",
    "\n",
    "* 3.1 训练 VAE (无标签数据可用)\n",
    "\n",
    "当你对无标注数据做川练时，只要做VAE的重构损失 + KL 散度即可:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\mathrm{VAE}}=\\|x-\\hat{x}\\|^2(\\text { or } \\mathrm{BCE})+\\mathrm{KL}\\left[q_\\phi(z \\mid x) \\| p(z)\\right]\n",
    "$$\n",
    "\n",
    "- 重构损失: $\\|x-\\hat{x}\\|^2$ 或二元交叉摘（BCE）等度量，让解码器输出的 $\\hat{x}$ 与原图 $x$ 尽量相似。\n",
    "- KL 散度：让编码器的潜在分布 $q_\\phi(z \\mid x)$ 靠近先验 $p(z)$ （通常是 $\\mathcal{N}(0, I)$ ）。\n",
    "\n",
    "无标注数据上我们不计算分类损失，因为没有标签，但可以昭样通过 VAE 重构去学习潜在表示。\n",
    "\n",
    "* 3.2 训练分类器（需有标注数据）\n",
    "\n",
    "当你对有标注数据进行训练时，同时更新VAE 及分类器，因为分类器要用到编码器的输出：\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text {Classifier }}=\\text { CrossEntropy }(\\text { logits }, y)\n",
    "$$\n",
    "\n",
    "\n",
    "其中:\n",
    "- logits = classifier(encoder(x)) (或 reparameterized $z$ )。\n",
    "- $y$ 是图像对应的真实类别标签( $0 \\sim 9$ )。\n",
    "\n",
    "这个部分只在\"有标签数据\"上存在。\n",
    "\n",
    "* 3.3 总损失\n",
    "\n",
    "综合起来，你可以同时或交替地对有标签 / 无标签批次进行更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(x, x_recon, mu, logvar):\n",
    "    # x: [B, 3, 32, 32]\n",
    "    # x_recon: [B, 3, 32, 32]\n",
    "    # mu, logvar: [B, latent_dim]\n",
    "\n",
    "    # 1) 重构损失 - 使用 BCE\n",
    "    recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum') / x.size(0) \n",
    "    # 或者 mean() 并再根据需要调节平衡\n",
    "    \n",
    "    # 2) KL 散度\n",
    "    # KL = 0.5 * sum( exp(logvar) + mu^2 - 1 - logvar )\n",
    "    kl_divergence = 0.5 * torch.mean(torch.sum(torch.exp(logvar) + mu**2 - 1. - logvar, dim=1))\n",
    "    \n",
    "    return recon_loss + kl_divergence, recon_loss, kl_divergence\n",
    "\n",
    "\n",
    "def classifier_loss_function(logits, y):\n",
    "    return F.cross_entropy(logits, y)  \n",
    "\n",
    "# ---------------------------\n",
    "# 8. 定义验证函数\n",
    "# ---------------------------\n",
    "\n",
    "def evaluate_on_valset(model, val_loader):\n",
    "    \"\"\"\n",
    "    在验证集上评估分类准确率\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            logits = model.forward_classifier(x_val)  # [B, num_classes]\n",
    "            preds = torch.argmax(logits, dim=1)       # [B]\n",
    "            correct += (preds == y_val).sum().item()\n",
    "            total += y_val.size(0)\n",
    "    acc = correct / total\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 9. 实现 Baseline 和 Semi-Supervised 训练\n",
    "# ---------------------------\n",
    "\n",
    "def train_baseline(model, labeled_loader, val_loader, epochs=10, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Baseline 训练：仅使用有标签数据训练模型\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_clf = 0.0\n",
    "        \n",
    "        for x_labeled, y_labeled in labeled_loader:\n",
    "            x_labeled = x_labeled.to(device)\n",
    "            y_labeled = y_labeled.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 分类器前向\n",
    "            logits = model.forward_classifier(x_labeled)\n",
    "            clf_loss = classifier_loss_function(logits, y_labeled)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            clf_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += clf_loss.item()\n",
    "            total_clf += clf_loss.item()\n",
    "        \n",
    "        # 计算平均损失\n",
    "        avg_loss = total_loss / len(labeled_loader)\n",
    "        avg_clf = total_clf / len(labeled_loader)\n",
    "        \n",
    "        # 验证集评估\n",
    "        val_acc = evaluate_on_valset(model, val_loader)\n",
    "        \n",
    "        print(f\"[Baseline] Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Clf: {avg_clf:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_semi_supervised(model, labeled_loader, unlabeled_loader, val_loader, epochs=10, lr=1e-3, lambda_unsupervised=1.0, confidence_threshold=0.8):\n",
    "    \"\"\"\n",
    "    半监督训练：同时使用有标签和无标签数据\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_recon = 0.0\n",
    "        total_kl = 0.0\n",
    "        total_clf = 0.0\n",
    "        total_unsupervised = 0.0\n",
    "        \n",
    "        # a) 有标签数据训练\n",
    "        for x_labeled, y_labeled in labeled_loader:\n",
    "            x_labeled = x_labeled.to(device)\n",
    "            y_labeled = y_labeled.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # VAE 前向\n",
    "            x_recon, mu, logvar, z = model.forward_vae(x_labeled)\n",
    "            vae_loss, recon_loss, kl_div = vae_loss_function(x_labeled, x_recon, mu, logvar)\n",
    "            \n",
    "            # 分类器前向\n",
    "            logits = model.forward_classifier(x_labeled)\n",
    "            clf_loss = classifier_loss_function(logits, y_labeled)\n",
    "            \n",
    "            # 合并损失\n",
    "            total_batch_loss = vae_loss + clf_loss  \n",
    "            total_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += total_batch_loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            total_kl += kl_div.item()\n",
    "            total_clf += clf_loss.item()\n",
    "\n",
    "        # b) 无标签数据训练（伪标签）\n",
    "        for x_unlabeled in unlabeled_loader:\n",
    "            x_unlabeled = x_unlabeled.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 生成伪标签\n",
    "            logits = model.forward_classifier(x_unlabeled)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            max_probs, pseudo_labels = torch.max(probs, dim=-1)\n",
    "            \n",
    "            # 只使用高置信度的伪标签\n",
    "            high_confidence_mask = max_probs > confidence_threshold\n",
    "            if high_confidence_mask.sum() > 0:\n",
    "                pseudo_labels = pseudo_labels[high_confidence_mask]\n",
    "                x_unlabeled = x_unlabeled[high_confidence_mask]\n",
    "                \n",
    "                # 计算无标签数据的分类损失\n",
    "                clf_loss = classifier_loss_function(logits[high_confidence_mask], pseudo_labels)\n",
    "                \n",
    "                # 总损失 = 无标签数据损失 + 有标签数据损失\n",
    "                total_unsupervised_loss = lambda_unsupervised * clf_loss\n",
    "                total_unsupervised_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_unsupervised += total_unsupervised_loss.item()\n",
    "\n",
    "        # 计算平均损失\n",
    "        avg_loss = total_loss / len(labeled_loader)\n",
    "        avg_recon = total_recon / len(labeled_loader)\n",
    "        avg_kl = total_kl / len(labeled_loader)\n",
    "        avg_clf = total_clf / len(labeled_loader)\n",
    "        avg_unsupervised = total_unsupervised / len(unlabeled_loader)\n",
    "\n",
    "        # 验证集评估\n",
    "        val_acc = evaluate_on_valset(model, val_loader)\n",
    "        \n",
    "        print(f\"[Semi-Supervised] Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}, Clf: {avg_clf:.4f}, Unsupervised: {avg_unsupervised:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始 Baseline 训练（仅有标签数据）...\n",
      "[Baseline] Epoch 1/10, Loss: 2.3153, Clf: 2.3153, Val Acc: 0.1000\n",
      "[Baseline] Epoch 2/10, Loss: 2.3001, Clf: 2.3001, Val Acc: 0.1632\n",
      "[Baseline] Epoch 3/10, Loss: 2.2466, Clf: 2.2466, Val Acc: 0.1284\n",
      "[Baseline] Epoch 4/10, Loss: 2.2630, Clf: 2.2630, Val Acc: 0.1401\n",
      "[Baseline] Epoch 5/10, Loss: 2.2094, Clf: 2.2094, Val Acc: 0.1573\n",
      "[Baseline] Epoch 6/10, Loss: 2.1534, Clf: 2.1534, Val Acc: 0.1925\n",
      "[Baseline] Epoch 7/10, Loss: 2.1225, Clf: 2.1225, Val Acc: 0.2331\n",
      "[Baseline] Epoch 8/10, Loss: 2.0578, Clf: 2.0578, Val Acc: 0.2203\n",
      "[Baseline] Epoch 9/10, Loss: 2.0038, Clf: 2.0038, Val Acc: 0.2675\n",
      "[Baseline] Epoch 10/10, Loss: 1.8889, Clf: 1.8889, Val Acc: 0.2509\n",
      "\n",
      "开始 半监督训练（有标签 + 无标签数据）...\n",
      "[Semi-Supervised] Epoch 1/10, Loss: 2130.3845, Clf: 2.3115, Unsupervised: 0.0000, Val Acc: 0.0872\n",
      "[Semi-Supervised] Epoch 2/10, Loss: 2125.7730, Clf: 2.2873, Unsupervised: 0.0000, Val Acc: 0.1113\n",
      "[Semi-Supervised] Epoch 3/10, Loss: 2106.7699, Clf: 2.2789, Unsupervised: 0.0000, Val Acc: 0.1629\n",
      "[Semi-Supervised] Epoch 4/10, Loss: 2088.1254, Clf: 2.2613, Unsupervised: 0.0000, Val Acc: 0.1784\n",
      "[Semi-Supervised] Epoch 5/10, Loss: 2069.3262, Clf: 2.2282, Unsupervised: 0.0000, Val Acc: 0.2065\n",
      "[Semi-Supervised] Epoch 6/10, Loss: 2087.0404, Clf: 2.1865, Unsupervised: 0.0000, Val Acc: 0.1421\n",
      "[Semi-Supervised] Epoch 7/10, Loss: 2071.9022, Clf: 2.1797, Unsupervised: 0.0000, Val Acc: 0.1959\n",
      "[Semi-Supervised] Epoch 8/10, Loss: 2049.9933, Clf: 2.1584, Unsupervised: 0.0000, Val Acc: 0.2161\n",
      "[Semi-Supervised] Epoch 9/10, Loss: 2037.8330, Clf: 2.1724, Unsupervised: 0.0000, Val Acc: 0.1703\n",
      "[Semi-Supervised] Epoch 10/10, Loss: 2030.8822, Clf: 2.1445, Unsupervised: 0.0000, Val Acc: 0.2203\n",
      "\n",
      "最终对比结果:\n",
      "  Baseline 准确率 = 0.2509\n",
      "  半监督准确率 = 0.2203\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 10. 运行训练并对比\n",
    "# ---------------------------\n",
    "\n",
    "def main():\n",
    "    # 实例化两个独立的模型\n",
    "    model_baseline = VAE_Classifier(latent_dim=latent_dim, num_classes=num_classes).to(device)\n",
    "    model_semi = VAE_Classifier(latent_dim=latent_dim, num_classes=num_classes).to(device)\n",
    "    \n",
    "    # 定义训练参数\n",
    "    epochs = 10\n",
    "    learning_rate = 1e-2\n",
    "    \n",
    "    print(\"开始 Baseline 训练（仅有标签数据）...\")\n",
    "    model_baseline = train_baseline(model_baseline, labeled_loader, val_loader, epochs=epochs, lr=learning_rate)\n",
    "    \n",
    "    print(\"\\n开始 半监督训练（有标签 + 无标签数据）...\")\n",
    "    model_semi = train_semi_supervised(model_semi, labeled_loader, unlabeled_loader, val_loader, epochs=epochs, lr=learning_rate)\n",
    "    \n",
    "    # 最终评估对比\n",
    "    baseline_acc = evaluate_on_valset(model_baseline, val_loader)\n",
    "    semi_acc = evaluate_on_valset(model_semi, val_loader)\n",
    "    \n",
    "    print(f\"\\n最终对比结果:\\n  Baseline 准确率 = {baseline_acc:.4f}\\n  半监督准确率 = {semi_acc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终对比结果显示，Baseline模型的准确率为0.2509，而半监督模型的准确率为0.2203。需要注意的是，这个项目仅是一个演示（demo），其主要目的是为了讲解半监督训练的基本原理和工作流程，而不是追求最终的精度表现。半监督训练的效果通常依赖于大量的数据、细致的参数调优以及合适的模型设计。在实际应用中，半监督学习可以通过利用未标注数据来提升模型性能，但这一过程需要经过反复的实验和调整。因此，当前的结果并不代表半监督学习的最终潜力，而是为进一步探索和优化提供了一个起点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
    "---\n",
    "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
    "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
    "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/\n",
    "* <a href=\"https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/\">Jason Brownlee - Why Initialize a Neural Network with Random Weights?</a>\n",
    "* <a href=\"https://openai.com/blog/deep-double-descent/\">OpenAI - Deep Double Descent</a>\n",
    "* <a href=\"https://taldatech.github.io\">Tal Daniel</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
